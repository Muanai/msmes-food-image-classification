{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077917db",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-09T05:32:08.904719Z",
          "iopub.status.busy": "2025-11-09T05:32:08.904490Z",
          "iopub.status.idle": "2025-11-09T11:02:41.728915Z",
          "shell.execute_reply": "2025-11-09T11:02:41.727919Z"
        },
        "papermill": {
          "duration": 19832.828318,
          "end_time": "2025-11-09T11:02:41.730099",
          "exception": false,
          "start_time": "2025-11-09T05:32:08.901781",
          "status": "completed"
        },
        "tags": [],
        "id": "077917db"
      },
      "outputs": [],
      "source": [
        "import os, gc, random, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import timm\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.data import Mixup\n",
        "try:\n",
        "    from timm.utils import ModelEmaV2\n",
        "except:\n",
        "    ModelEmaV2 = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG\n",
        "\n",
        "TRAIN_DIR = \"/kaggle/input/action-dm-dataset/action-dm-dataset_2/train\"\n",
        "TEST_DIR  = \"/kaggle/input/action-dm-dataset/action-dm-dataset_2/test/test\"\n",
        "MODEL_SAVE_PATH = \"swin_large_mixcut_ema_best.pth\"\n",
        "OUT_FILE = \"submission_swin_large_tta_mixcut.csv\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 4\n",
        "IMG_SIZE = 384\n",
        "EPOCHS = 20\n",
        "BACKBONE = \"swinv2_large_window12to24_192to384_22kft1k\"\n",
        "BASE_LR = 5e-5\n",
        "WARMUP_EPOCHS = 2\n",
        "\n",
        "USE_EMA = True\n",
        "USE_MIXUP = True\n",
        "USE_TTA = True\n",
        "\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "print(\"BACKBONE:\", BACKBONE)"
      ],
      "metadata": {
        "id": "WV05DnpgfQmi"
      },
      "id": "WV05DnpgfQmi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSFORMS\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.25),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.15))\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tta_tfms = [\n",
        "    val_tfms,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]"
      ],
      "metadata": {
        "id": "kPObH9WVfK4c"
      },
      "id": "kPObH9WVfK4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, paths, labels=None, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.labels is not None:\n",
        "            return img, int(self.labels[idx])\n",
        "        else:\n",
        "            return img, os.path.basename(self.paths[idx])"
      ],
      "metadata": {
        "id": "U_pTJc0YfFxT"
      },
      "id": "U_pTJc0YfFxT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "\n",
        "def get_model(backbone_name, n_classes, pretrained=True):\n",
        "    print(\"Loading model:\", backbone_name)\n",
        "    model = timm.create_model(backbone_name, pretrained=pretrained, num_classes=n_classes)\n",
        "    if hasattr(model, \"set_grad_checkpointing\"):\n",
        "        try:\n",
        "            model.set_grad_checkpointing(True)\n",
        "            print(\" - grad checkpointing ON\")\n",
        "        except Exception:\n",
        "            pass\n",
        "    return model"
      ],
      "metadata": {
        "id": "9tpc3OxofByL"
      },
      "id": "9tpc3OxofByL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LR schedule\n",
        "\n",
        "def make_scheduler(optimizer, total_epochs, steps_per_epoch, base_lr, warmup_epochs):\n",
        "    total_steps = total_epochs * steps_per_epoch\n",
        "    warmup_steps = max(1, warmup_epochs * steps_per_epoch)\n",
        "\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        # cosine from 1 -> 0\n",
        "        progress = float(step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "    return LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "C516OVd-e7g5"
      },
      "id": "C516OVd-e7g5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return (correct / total) if total>0 else 0.0, (val_loss / total) if total>0 else 0.0"
      ],
      "metadata": {
        "id": "QxxjM5Ixe34S"
      },
      "id": "QxxjM5Ixe34S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN LOOP\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs, save_path, mixup_fn=None, use_ema=USE_EMA):\n",
        "    soft_loss_fn = SoftTargetCrossEntropy()\n",
        "    hard_loss_fn = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=BASE_LR, weight_decay=0.01)\n",
        "    scheduler = make_scheduler(optimizer, total_epochs=epochs, steps_per_epoch=len(train_loader),\n",
        "                               base_lr=BASE_LR, warmup_epochs=WARMUP_EPOCHS)\n",
        "    scaler = torch.cuda.amp.GradScaler() if DEVICE.startswith(\"cuda\") else torch.cuda.amp.GradScaler()\n",
        "    ema_model = None\n",
        "    if use_ema and ModelEmaV2 is not None:\n",
        "        try:\n",
        "            ema_model = ModelEmaV2(model, decay=0.9999)\n",
        "            print(\"EMA enabled\")\n",
        "        except Exception as e:\n",
        "            print(\"EMA init failed:\", e); ema_model = None\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, running_corrects, running_total = 0.0, 0, 0\n",
        "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for step, (imgs, labels) in pbar:\n",
        "            imgs = imgs.to(DEVICE); labels = labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            if mixup_fn is not None:\n",
        "                imgs, labels = mixup_fn(imgs, labels)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(imgs)\n",
        "                if mixup_fn is not None:\n",
        "                    loss = soft_loss_fn(outputs, labels)\n",
        "                    try:\n",
        "                        hard_targets = torch.argmax(labels, dim=1)\n",
        "                    except Exception:\n",
        "                        hard_targets = None\n",
        "                else:\n",
        "                    loss = hard_loss_fn(outputs, labels)\n",
        "                    hard_targets = labels\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            try:\n",
        "                scaler.unscale_(optimizer)\n",
        "            except Exception:\n",
        "                pass\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            scheduler.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if ema_model is not None:\n",
        "                try:\n",
        "                    ema_model.update(model)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = torch.argmax(outputs.detach(), dim=1)\n",
        "                if hard_targets is not None:\n",
        "                    running_corrects += (preds == hard_targets).sum().item()\n",
        "                running_total += imgs.size(0)\n",
        "                running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "            pbar.set_postfix(loss=(running_loss / running_total), acc=(running_corrects / running_total if running_total>0 else 0.0))\n",
        "\n",
        "        if ema_model is not None and hasattr(ema_model, \"module\"):\n",
        "            model_for_eval = ema_model.module\n",
        "        elif ema_model is not None and hasattr(ema_model, \"state_dict\"):\n",
        "            model_for_eval = model\n",
        "        else:\n",
        "            model_for_eval = model\n",
        "\n",
        "        val_acc, val_loss = validate(model_for_eval, val_loader, hard_loss_fn)\n",
        "        print(f\"[Epoch {epoch+1}] val_acc={val_acc:.4f} val_loss={val_loss:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            try:\n",
        "                if ema_model is not None and hasattr(ema_model, \"module\"):\n",
        "                    torch.save(model_for_eval.state_dict(), save_path)\n",
        "                else:\n",
        "                    torch.save(model.state_dict(), save_path)\n",
        "                print(f\"Saved best model -> {save_path} (val_acc={best_val_acc:.4f})\")\n",
        "            except Exception as e:\n",
        "                print(\"Save failed:\", e)\n",
        "\n",
        "    print(\"Training finished. Best val acc:\", best_val_acc)"
      ],
      "metadata": {
        "id": "46ctcjKFeZTd"
      },
      "id": "46ctcjKFeZTd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN\n",
        "\n",
        "full = datasets.ImageFolder(TRAIN_DIR)\n",
        "n_classes = len(full.classes)\n",
        "paths = [p for p, _ in full.samples]\n",
        "labels = [int(l) for _, l in full.samples]\n",
        "\n",
        "indices = list(range(len(paths)))\n",
        "random.shuffle(indices)\n",
        "split = int(0.9 * len(indices))\n",
        "train_idx = indices[:split]\n",
        "val_idx = indices[split:]\n",
        "\n",
        "train_paths = [paths[i] for i in train_idx]\n",
        "train_labels = [labels[i] for i in train_idx]\n",
        "val_paths = [paths[i] for i in val_idx]\n",
        "val_labels = [labels[i] for i in val_idx]\n",
        "\n",
        "train_ds = SimpleImageDataset(train_paths, train_labels, train_tfms)\n",
        "val_ds = SimpleImageDataset(val_paths, val_labels, val_tfms)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "model = get_model(BACKBONE, n_classes, pretrained=True).to(DEVICE)\n",
        "\n",
        "# Mixup/Cutmix\n",
        "mixup_fn = None\n",
        "if USE_MIXUP:\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=0.4, cutmix_alpha=1.0,\n",
        "        prob=1.0, switch_prob=0.5,\n",
        "        label_smoothing=0.1, num_classes=n_classes\n",
        "    )\n",
        "    print(\"Mixup/CutMix enabled\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, EPOCHS, MODEL_SAVE_PATH, mixup_fn=mixup_fn)"
      ],
      "metadata": {
        "id": "aTgVsa-0ePXR"
      },
      "id": "aTgVsa-0ePXR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INFERENCE + TTA\n",
        "\n",
        "if os.path.exists(MODEL_SAVE_PATH):\n",
        "    sd = torch.load(MODEL_SAVE_PATH, map_location=DEVICE)\n",
        "    try:\n",
        "        model.load_state_dict(sd)\n",
        "    except Exception:\n",
        "        model.load_state_dict(sd, strict=False)\n",
        "model.eval()\n",
        "\n",
        "test_imgs = sorted(glob(os.path.join(TEST_DIR, \"*\")))\n",
        "rows = []\n",
        "\n",
        "model_for_infer = model\n",
        "\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "    for p in tqdm(test_imgs, desc=\"Inferencing with TTA\"):\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        preds = []\n",
        "        if USE_TTA:\n",
        "            for tta in tta_tfms:\n",
        "                x = tta(img).unsqueeze(0).to(DEVICE)\n",
        "                out = F.softmax(model_for_infer(x), dim=1)\n",
        "                preds.append(out)\n",
        "            avg_pred = torch.stack(preds, dim=0).mean(0)\n",
        "        else:\n",
        "            x = val_tfms(img).unsqueeze(0).to(DEVICE)\n",
        "            avg_pred = F.softmax(model_for_infer(x), dim=1)\n",
        "        idx = torch.argmax(avg_pred, dim=1).item()\n",
        "        label = full.classes[idx]\n",
        "        rows.append({\"ID\": os.path.basename(p), \"label\": label})\n",
        "\n",
        "pd.DataFrame(rows).to_csv(OUT_FILE, index=False)\n",
        "print(\"âœ… Submission saved to\", OUT_FILE)"
      ],
      "metadata": {
        "id": "iSFv2Zd_d_D9"
      },
      "id": "iSFv2Zd_d_D9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8619147,
          "sourceId": 13583632,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 19840.135867,
      "end_time": "2025-11-09T11:02:45.314151",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-09T05:32:05.178284",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}