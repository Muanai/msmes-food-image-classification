{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13583632,
          "sourceType": "datasetVersion",
          "datasetId": 8619147
        },
        {
          "sourceId": 13668924,
          "sourceType": "datasetVersion",
          "datasetId": 8691038
        },
        {
          "sourceId": 13678935,
          "sourceType": "datasetVersion",
          "datasetId": 8698506
        },
        {
          "sourceId": 13680117,
          "sourceType": "datasetVersion",
          "datasetId": 8699382
        },
        {
          "sourceId": 13688159,
          "sourceType": "datasetVersion",
          "datasetId": 8705654
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. SETUP\n",
        "\n",
        "import os, gc, torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms, datasets\n",
        "import timm\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "TRAIN_DIR = \"/kaggle/input/action-dm-dataset/action-dm-dataset_2/train\"\n",
        "TEST_DIR  = \"/kaggle/input/action-dm-dataset/action-dm-dataset_2/test/test\"\n",
        "OUT_FILE  = \"submission_ensemble_rank4_boosted.csv\"\n",
        "\n",
        "MODEL_PATHS = [\n",
        "    \"/kaggle/input/saved-best-models/swin_large_mixcut_ema_best.pth\",\n",
        "    \"/kaggle/input/saved-best-models/best_model_fold_0.pth\",\n",
        "    \"/kaggle/input/saved-best-models/best_model_fold_1.pth\",\n",
        "    \"/kaggle/input/saved-best-models/best_model_fold_2.pth\",\n",
        "]\n",
        "\n",
        "BACKBONES = [\n",
        "    \"swinv2_large_window12to24_192to384_22kft1k\",\n",
        "    \"convnextv2_large.fcmae_ft_in22k_in1k\",\n",
        "    \"convnextv2_large.fcmae_ft_in22k_in1k\",\n",
        "    \"convnextv2_large.fcmae_ft_in22k_in1k\",\n",
        "]\n",
        "\n",
        "VAL_ACCS = [0.9190, 0.9118, 0.9201, 0.9239]\n",
        "weights = torch.tensor(VAL_ACCS) / sum(VAL_ACCS)\n",
        "weights = weights.to(DEVICE)\n",
        "\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 8\n",
        "TEMPERATURE = 1.6\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-10T14:03:31.207747Z",
          "iopub.execute_input": "2025-11-10T14:03:31.208542Z",
          "iopub.status.idle": "2025-11-10T14:43:38.942457Z",
          "shell.execute_reply.started": "2025-11-10T14:03:31.208515Z",
          "shell.execute_reply": "2025-11-10T14:43:38.941783Z"
        },
        "id": "jY6UMgenqXvy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. IMPROVED TTA (lebih natural)\n",
        "\n",
        "tta_tfms = [\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.92, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]"
      ],
      "metadata": {
        "id": "71PhTpxFqqql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. LOAD CLASSES & MODELS\n",
        "\n",
        "trainset = datasets.ImageFolder(TRAIN_DIR)\n",
        "CLASSES = trainset.classes\n",
        "n_classes = len(CLASSES)\n",
        "\n",
        "def load_model(backbone, num_classes, path):\n",
        "    print(f\"Loading {backbone} from {os.path.basename(path)}\")\n",
        "    model = timm.create_model(backbone, pretrained=False, num_classes=num_classes)\n",
        "    state = torch.load(path, map_location=DEVICE)\n",
        "    model.load_state_dict(state, strict=False)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "models = [load_model(bb, n_classes, p) for bb, p in zip(BACKBONES, MODEL_PATHS)]\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_grad_enabled(False)"
      ],
      "metadata": {
        "id": "rMnJla-vqmqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. INFERENCE + GEOMETRIC ENSEMBLE\n",
        "\n",
        "test_imgs = sorted(glob(os.path.join(TEST_DIR, \"*\")))\n",
        "results = []\n",
        "\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "    for img_path in tqdm(test_imgs, desc=\"Inferencing (Boosted Rank 4 Ensemble)\"):\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        probs_per_model = []\n",
        "        for model in models:\n",
        "            probs_tta = []\n",
        "            for tta in tta_tfms:\n",
        "                x = tta(img).unsqueeze(0).to(DEVICE, non_blocking=True)\n",
        "                logits = model(x)\n",
        "                probs = F.softmax(logits / TEMPERATURE, dim=1)\n",
        "                probs_tta.append(probs)\n",
        "            probs_tta = torch.stack(probs_tta).mean(0)\n",
        "            probs_per_model.append(probs_tta)\n",
        "\n",
        "        probs_per_model = torch.stack(probs_per_model)\n",
        "        weighted_log_probs = torch.log(probs_per_model + 1e-8) * weights[:, None, None]\n",
        "        geo_mean = torch.exp(weighted_log_probs.sum(0))\n",
        "        probs = geo_mean / geo_mean.sum(dim=1, keepdim=True)\n",
        "\n",
        "        idx = torch.argmax(probs, dim=1).item()\n",
        "        label = CLASSES[idx]\n",
        "        results.append({\"ID\": os.path.basename(img_path), \"label\": label})"
      ],
      "metadata": {
        "id": "_505zaHrqgq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. SAVE SUBMISSION\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(OUT_FILE, index=False)\n",
        "print(f\"âœ… Saved boosted ensemble submission to {OUT_FILE}\")"
      ],
      "metadata": {
        "id": "EQbNOc5-qZxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}