{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d97478f",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-09T18:00:29.026617Z",
          "iopub.status.busy": "2025-11-09T18:00:29.026419Z",
          "iopub.status.idle": "2025-11-09T20:28:21.092753Z",
          "shell.execute_reply": "2025-11-09T20:28:21.091796Z"
        },
        "papermill": {
          "duration": 8872.070655,
          "end_time": "2025-11-09T20:28:21.094137",
          "exception": false,
          "start_time": "2025-11-09T18:00:29.023482",
          "status": "completed"
        },
        "tags": [],
        "id": "8d97478f"
      },
      "outputs": [],
      "source": [
        "import os, gc, random, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import timm\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from timm.data import Mixup\n",
        "try:\n",
        "    from timm.utils import ModelEmaV2\n",
        "except Exception:\n",
        "    ModelEmaV2 = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG (tweak if needed)\n",
        "\n",
        "TRAIN_DIR = \"/kaggle/input/action-dm-dataset/action-dm-dataset_2/train\"\n",
        "TEST_DIR  = \"/kaggle/input/action-dm-dataset/action-dm-dataset_2/test/test\"\n",
        "MODEL_SAVE_PATH = \"efficientnetv2_l_best.pth\"\n",
        "OUT_FILE = \"submission_efficientnetv2_l_tta.csv\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 4\n",
        "IMG_SIZE = 480\n",
        "EPOCHS = 25\n",
        "BACKBONE = \"tf_efficientnetv2_l_in21ft1k\"\n",
        "BASE_LR = 1e-4\n",
        "WARMUP_EPOCHS = 1\n",
        "\n",
        "USE_EMA = True\n",
        "USE_MIXUP = True\n",
        "USE_TTA = True\n",
        "\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "print(\"BACKBONE:\", BACKBONE)"
      ],
      "metadata": {
        "id": "FiUjsbT4hXcQ"
      },
      "id": "FiUjsbT4hXcQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSFORMS & TTA\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.1),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.18),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02,0.12))\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "tta_tfms = [\n",
        "    val_tfms,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE * 1.14)),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9,1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "]"
      ],
      "metadata": {
        "id": "oGfKK_TBhSL7"
      },
      "id": "oGfKK_TBhSL7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, paths, labels=None, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.labels is not None:\n",
        "            return img, int(self.labels[idx])\n",
        "        else:\n",
        "            return img, os.path.basename(self.paths[idx])"
      ],
      "metadata": {
        "id": "SffskOx0hL51"
      },
      "id": "SffskOx0hL51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL helper\n",
        "\n",
        "def get_model(backbone_name, n_classes, pretrained=True):\n",
        "    print(\"=> create model:\", backbone_name)\n",
        "    model = timm.create_model(backbone_name, pretrained=pretrained, num_classes=n_classes)\n",
        "    try:\n",
        "        if hasattr(model, \"set_grad_checkpointing\"):\n",
        "            model.set_grad_checkpointing(True)\n",
        "            print(\" - grad checkpointing enabled\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    return model"
      ],
      "metadata": {
        "id": "jMXbQDThhHFQ"
      },
      "id": "jMXbQDThhHFQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LR: warmup -> cosine schedule (per-batch)\n",
        "\n",
        "def make_scheduler(optimizer, total_epochs, steps_per_epoch, warmup_epochs):\n",
        "    total_steps = total_epochs * steps_per_epoch\n",
        "    warmup_steps = max(1, warmup_epochs * steps_per_epoch)\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        progress = float(step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "    return LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "mvk53GXyhCBH"
      },
      "id": "mvk53GXyhCBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATE\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    loss_sum = 0.0; correct = 0; total = 0\n",
        "    device = DEVICE\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device); labels = labels.to(device)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss_sum += loss.item() * imgs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += imgs.size(0)\n",
        "    return (correct/total) if total>0 else 0.0, (loss_sum/total) if total>0 else 0.0"
      ],
      "metadata": {
        "id": "P27RCdZng-e2"
      },
      "id": "P27RCdZng-e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN LOOP\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs, save_path, mixup_fn=None, use_ema=USE_EMA):\n",
        "    device = DEVICE\n",
        "    soft_loss = SoftTargetCrossEntropy()\n",
        "    hard_loss = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=BASE_LR, weight_decay=0.01)\n",
        "    scheduler = make_scheduler(optimizer, total_epochs=epochs, steps_per_epoch=len(train_loader), warmup_epochs=WARMUP_EPOCHS)\n",
        "    scaler = torch.cuda.amp.GradScaler() if device.startswith(\"cuda\") else None\n",
        "\n",
        "    ema_model = None\n",
        "    if use_ema and ModelEmaV2 is not None:\n",
        "        try:\n",
        "            ema_model = ModelEmaV2(model, decay=0.9999)\n",
        "            print(\"=> EMA enabled\")\n",
        "        except Exception as e:\n",
        "            print(\"=> EMA init failed:\", e); ema_model = None\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0; running_correct = 0; running_total = 0\n",
        "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for step, (imgs, labels) in pbar:\n",
        "            imgs = imgs.to(device); labels = labels.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            if mixup_fn is not None:\n",
        "                imgs, labels_mixed = mixup_fn(imgs, labels)\n",
        "                targets = labels_mixed\n",
        "                use_soft = True\n",
        "            else:\n",
        "                targets = labels\n",
        "                use_soft = False\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits = model(imgs)\n",
        "                if use_soft:\n",
        "                    loss = soft_loss(logits, targets)\n",
        "                    try:\n",
        "                        hard_targets = targets.argmax(dim=1)\n",
        "                    except Exception:\n",
        "                        hard_targets = None\n",
        "                else:\n",
        "                    loss = hard_loss(logits, targets)\n",
        "                    hard_targets = targets\n",
        "\n",
        "            if scaler is not None:\n",
        "                scaler.scale(loss).backward()\n",
        "                try:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if ema_model is not None:\n",
        "                try:\n",
        "                    ema_model.update(model)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = logits.argmax(dim=1)\n",
        "                if hard_targets is not None:\n",
        "                    running_correct += (preds == hard_targets).sum().item()\n",
        "                running_total += imgs.size(0)\n",
        "                running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "            pbar.set_postfix(loss=(running_loss/running_total if running_total>0 else 0.0),\n",
        "                             acc=(running_correct/running_total if running_total>0 else 0.0),\n",
        "                             lr=optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        if ema_model is not None and hasattr(ema_model, \"module\"):\n",
        "            model_for_eval = ema_model.module\n",
        "        else:\n",
        "            model_for_eval = model\n",
        "\n",
        "        val_acc, val_loss = validate(model_for_eval, val_loader, hard_loss)\n",
        "        print(f\"[Epoch {epoch+1}] val_acc={val_acc:.4f} val_loss={val_loss:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            try:\n",
        "                if ema_model is not None and hasattr(ema_model, \"module\"):\n",
        "                    torch.save(model_for_eval.state_dict(), save_path)\n",
        "                elif ema_model is not None and hasattr(ema_model, \"state_dict\"):\n",
        "                    torch.save(ema_model.state_dict(), save_path)\n",
        "                else:\n",
        "                    torch.save(model.state_dict(), save_path)\n",
        "                print(f\"=> Saved best model to {save_path} (val_acc={best_val_acc:.4f})\")\n",
        "            except Exception as e:\n",
        "                print(\"Save failed:\", e)\n",
        "\n",
        "    print(\"Training complete. Best val acc:\", best_val_acc)"
      ],
      "metadata": {
        "id": "xVsVQpMAguS9"
      },
      "id": "xVsVQpMAguS9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN: prepare data, model, mixup\n",
        "\n",
        "full = datasets.ImageFolder(TRAIN_DIR)\n",
        "n_classes = len(full.classes)\n",
        "paths = [p for p,_ in full.samples]\n",
        "labels = [int(l) for _,l in full.samples]\n",
        "\n",
        "indices = list(range(len(paths)))\n",
        "random.shuffle(indices)\n",
        "split = int(0.9 * len(indices))\n",
        "train_idx = indices[:split]; val_idx = indices[split:]\n",
        "\n",
        "train_paths = [paths[i] for i in train_idx]; train_labels = [labels[i] for i in train_idx]\n",
        "val_paths   = [paths[i] for i in val_idx];   val_labels   = [labels[i] for i in val_idx]\n",
        "\n",
        "train_ds = SimpleImageDataset(train_paths, train_labels, train_tfms)\n",
        "val_ds   = SimpleImageDataset(val_paths,   val_labels,   val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "model = get_model(BACKBONE, n_classes, pretrained=True).to(DEVICE)\n",
        "\n",
        "mixup_fn = None\n",
        "if USE_MIXUP:\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=0.5,\n",
        "        cutmix_alpha=1.0,\n",
        "        prob=0.5,\n",
        "        switch_prob=0.5,\n",
        "        mode='batch',\n",
        "        label_smoothing=0.05,\n",
        "        num_classes=n_classes\n",
        "    )\n",
        "    print(\"Mixup/CutMix enabled (alpha=0.5)\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, EPOCHS, MODEL_SAVE_PATH, mixup_fn=mixup_fn, use_ema=USE_EMA)"
      ],
      "metadata": {
        "id": "6tLIfhAwgrTn"
      },
      "id": "6tLIfhAwgrTn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INFERENCE + TTA\n",
        "\n",
        "if os.path.exists(MODEL_SAVE_PATH):\n",
        "    sd = torch.load(MODEL_SAVE_PATH, map_location=DEVICE)\n",
        "    try:\n",
        "        model.load_state_dict(sd)\n",
        "    except Exception:\n",
        "        try:\n",
        "            model.load_state_dict(sd, strict=False)\n",
        "        except Exception:\n",
        "            print(\"Warning: can't fully load checkpoint with strict=False; continuing with partial load.\")\n",
        "\n",
        "model.eval()\n",
        "test_imgs = sorted(glob(os.path.join(TEST_DIR, \"*\")))\n",
        "rows = []\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "    for p in tqdm(test_imgs, desc=\"Inference with TTA\"):\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        if USE_TTA:\n",
        "            preds = []\n",
        "            for t in tta_tfms:\n",
        "                x = t(img).unsqueeze(0).to(DEVICE)\n",
        "                logits = model(x)\n",
        "                preds.append(logits)\n",
        "            avg_logits = torch.stack(preds, dim=0).mean(0)\n",
        "            probs = F.softmax(avg_logits, dim=1)\n",
        "        else:\n",
        "            x = val_tfms(img).unsqueeze(0).to(DEVICE)\n",
        "            probs = F.softmax(model(x), dim=1)\n",
        "        idx = torch.argmax(probs, dim=1).item()\n",
        "        rows.append({\"ID\": os.path.basename(p), \"label\": full.classes[idx]})\n",
        "\n",
        "pd.DataFrame(rows).to_csv(OUT_FILE, index=False)\n",
        "print(\"Saved submission:\", OUT_FILE)"
      ],
      "metadata": {
        "id": "Q2MjuXYPgapK"
      },
      "id": "Q2MjuXYPgapK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8619147,
          "sourceId": 13583632,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 8879.896697,
      "end_time": "2025-11-09T20:28:25.236425",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-09T18:00:25.339728",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}